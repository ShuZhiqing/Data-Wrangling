{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT5196 Task 2 in Assessment 1\n",
    "\n",
    "### Student Name: Zhiqing Shu\n",
    "### Student ID: 28217551\n",
    "\n",
    "#### Date: 27/03/2018\n",
    "\n",
    "Version: 3.0\n",
    "\n",
    "Environment: Python 3.6.4 and Anaconda 5.1.0 (64-bit)\n",
    "\n",
    "Libraries used: \n",
    "\n",
    "- pdftables.six 0.0.5 (for pdf file, included in Anaconda Python 3.6)\n",
    "- re 2.2.1 (for regular expression, included in Anaconda Python 3.6)\n",
    "- pandas (for dataframe, included in Anaconda Python 3.6)\n",
    "- numpy (for numpy array, included in Anaconda Python 3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is to extract data from a PDF File. The PDF file named **\"health.pdf\"** contains the children's health data over 202 countries in the world. The table spreads over four pages. The task is to extract the table and save them in a CSV file as where the first column contains the country names, and the following 22 columns contain various health information.\n",
    "\n",
    "The detailed requirements of this task is as the following:\n",
    "- must correctly parse and extract the table;\n",
    "- existing Python packages (like: pdfminer or pdftables) can be used, however, APIs (like pdftables_api), which requires API keys to push the PDF file to the server in order to get the file parsed, must not be used;\n",
    "- it is not required to extract the column labels. Except for the first column, which should be named as **\"Country Name\"**, the other columns should be indexed with integers as shown in the figure;\n",
    "- if the number followed by a character \"x\" in the pdf file, \"x\" must **be dropped in** your script;\n",
    "- script must be written in a Jupyter notebook named as **\"pdf.ipynb\"**;\n",
    "- the extracted table should be saved in a CSV file named as **\"health.csv\"**;\n",
    "- the input file must only be **\"health.pdf\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF is a document representation format and not a data format that is machine readable, like CSV, JSON, and XML, so specific libiraies are needed to extract data from the original PDF file. \n",
    "In this task, `pdftables.get_tables()` will be used to extract tables from PDF files. It is worthy to noticing that each row in the table is extracted and stored in a **list**.\n",
    "\n",
    "`re` is the library for regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdftables import get_tables\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parse Excel File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_tables()` [function](https://moodle.vle.monash.edu/mod/resource/view.php?id=4845787) returns each page of PDF file as a table, each of those tables have a list of rows, and each of those row is a contained list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFile = 'health.pdf'\n",
    "pdf = open(pdfFile, 'rb')\n",
    "tables = get_tables(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the first ten rows of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "    for row in table[:10]:\n",
    "        print(row)\n",
    "    print ('==========================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the last ten rows of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "    for row in table[-10:]:\n",
    "        print (row)\n",
    "    print ('==========================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the previous results, we can find that the first five lines and the last two  lines in the first three pages is not required to be presented in the final CSV file, so we need to delete it. Furthermore, apart from what should be removed as the previous pages, the forth one contains some data description, which will also be excluded.\n",
    "\n",
    "Before get the lines we need, we should know the index range of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tables[0]))\n",
    "print(len(tables[1]))\n",
    "print(len(tables[2]))\n",
    "print(len(tables[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For page_0, the index range we need is from 5 to 67, to exclude the first five line ( e.g. [5:] ) and last two line (e.g. the largest index is 68 (69-1), then 68-2 = 66,  so [:67], where 67 is optional). We can use the same way to process page_1 and page_2.\n",
    "However, the content of page_3 is a little different. Fortunately，the number of lines we need in page_3 can be easily count, just 14, so [5:19]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude titles and '-'\n",
    "page_0 = tables[0][5:67]\n",
    "page_1 = tables[1][5:68]\n",
    "page_2 = tables[2][5:68]\n",
    "page_3 = tables[3][5:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all information we need has been got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_0[:1])\n",
    "print(page_0[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_1[:1])\n",
    "print(page_1[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(page_2[:1])\n",
    "print(page_2[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_3[:1])\n",
    "print(page_3[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After carefully watching each page, we can find there are still some messiness remianing and the problems of page_0, page_1 and page_2 are very similar, just one merge of two adjacent data, but in page_0 and page_1 the merge occurs in the forth item, while in page_2, it occurs in the fifth one.\n",
    "\n",
    "According to the description in the original PDF, we can know that all data in this file is shown in persentage, and by using our commen sense, the range of all data should **between 0 to 100**. Apart from this, the unavailable data in this file is indicated as **'-'**, and the special characters **'x'** is also used to clarify the data referring to years or periods other than those specified in the column heading. As a result, we can write the regular expression in this way `r'(100|[1-9][0-9]?x?|[–])'`, and use `re.findall()` [function](https://docs.python.org/3/library/re.html) to return all non-overlapping matches of pattern in string, as a list of strings.\n",
    "\n",
    "Besides finding the matches, we also need to remove the matches and insert them into the correct position. Here, `pop()` [function](https://docs.python.org/3.6/tutorial/datastructures.html) will be used to remove the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(page_0)):\n",
    "    value = re.findall(r'(100|[1-9][0-9]?x?|–|0)', page_0[i].pop(4))\n",
    "    page_0[i] = page_0[i][:4] + value + page_0[i][4:]\n",
    "for i in range(len(page_1)):\n",
    "    value = re.findall(r'(100|[1-9][0-9]?x?|–|0)', page_1[i].pop(5))\n",
    "    page_1[i] = page_1[i][:5] + value + page_1[i][5:]\n",
    "for i in range(len(page_2)):\n",
    "    value = re.findall(r'(100|[1-9][0-9]?x?|–|0)', page_2[i].pop(4))\n",
    "    page_2[i] = page_2[i][:4] + value + page_2[i][4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check if each row in each page has been splited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the length of each row\n",
    "len(page_0[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rows in each page\n",
    "print(len(page_0))\n",
    "print(len(page_1))\n",
    "print(len(page_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if each row in every page has 23 items\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "num2 = 0\n",
    "for item in page_0:\n",
    "    if len(item) == 23:\n",
    "        num0 += 1\n",
    "print('num0:', num0)\n",
    "for item in page_1:\n",
    "    if len(item) == 23:\n",
    "        num1 += 1\n",
    "print('num1:', num1)\n",
    "for item in page_2:\n",
    "    if len(item) == 23:\n",
    "        num2 += 1\n",
    "print('num2:', num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the length of each row is same, we can merge the first three pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_0_to_2 = page_0 + page_1 + page_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if page_0_to_2 contains all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_0_to_2) == len(page_0) + len(page_1) + len(page_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to confirm all data in page_0_to_2 is processed correctly.\n",
    "The three regular expressions are worked in three columns under the heading named \"Use of basic sanitation service(%)\" of the PDF file, and the only difference is that in page_0 and page_2, it split the \"total\" and \"urban\" data, while in page_1, it splits the \"urban\" and \"rural\" data. It is a kind of common sense that the range of \"total\" should be between the \"urban\" and the \"rural\", so it can be a idea to check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in page_0_to_2:\n",
    "    if '–' not in item[5] and '–' not in item[6]:\n",
    "        # total > urban and total > rural\n",
    "        if int(item[4]) > int(item[5]) and int(item[4]) > int(item[6]): \n",
    "            print(item)\n",
    "        # total < urban and total < rural\n",
    "        elif int(item[4]) < int(item[5]) and int(item[4]) < int(item[6]):\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the abnormal row. Compared with the original PDF file, the error can be found, that is the merged \"`718\"` is splited into `\"71\"` and `\"8\"`, while in PDF they are `\"7\"` and `\"18\"`. This error is due to the fact that the digit of the after-spliting number is different, and the one-digit number is before the two-digit one. Since `? Quantifier` is greedy and will match between zero and one times, as many times as possible, so the first number splited through the regular expression used is always two-digit. We need to re-split the incorrect data as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in page_0_to_2:\n",
    "     if '–' not in item[5] and '–' not in item[6]:\n",
    "        # since 71 > 8 and 4, and the \"<\" situation not exists\n",
    "        if int(item[4]) > int(item[5]) and int(item[4])>int(item[6]):\n",
    "                data1 = re.findall(r'(\\d)(\\d)', item[4])\n",
    "                data2 = re.findall(r'(\\d)', item[5])\n",
    "                item[4] = data1[0][0]\n",
    "                item[5] = data1[0][1] + data2[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the problem has been fixed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_0_to_2:\n",
    "    if row[0] == \"Ethiopia\":\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another way to check the abnormal data. As we know `? Quantifier` is greedy, so we can suppose that the first number splited from the original data will always be two-digit, and the second one will always be one-digit, so we can just view those rows in which the sixth data is one-digit and check them.\n",
    "The code is as following: \n",
    "```\n",
    "for row in page_0_to_2:\n",
    "    if len(row[5]) < 2 and row[5] != '–': \n",
    "        print(row)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing the first three pages and checking the correctness, we can start parsing the last page.\n",
    "\n",
    "At first, we need to have a look of page_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "page_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many merge problems in page_3, taking the first row as an example:\n",
    "- 'Uganda397332' should be 'Uganda','39','73' and '32'\n",
    "- '192817938978' should be '19','28','17','93','89' and '78'\n",
    "- '07887' should be '0','78' and '78'\n",
    "- '4781' should be '47' and '81'\n",
    "\n",
    "These problem can be fixed one by one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Uganda397332' to 'Uganda','39','73' and '32'\n",
    "for item in range(len(page_3)):\n",
    "    data_0_to_3 = re.findall(r'([a-zA-Z()\\s]+|100|[1-9][0-9]?x?|–|0)', page_3[item].pop(0))\n",
    "    page_3[item] = data_0_to_3 + page_3[item][0:]\n",
    "page_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result seems to be right. However, we may still need to check whether the first item of each row have been splited to four data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "\n",
    "for item in page_3:\n",
    "    if len(item) == 15:\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct. Then, moving to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'192817938978' to '19','28','17','93','89' and '78'\n",
    "for item in range(len(page_3)):\n",
    "    data_4_to_9 = re.findall(r'(100|[1-9][0-9]?x?|–|0)', page_3[item].pop(4))\n",
    "    page_3[item] = page_3[item][:4] + data_4_to_9 + page_3[item][4:] \n",
    "page_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of each data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for item in page_3:\n",
    "    if len(item) == 20:\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct. Then, moving to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(page_3)):\n",
    "    data_15_to_17 = re.findall(r'(100|[1-9][0-9]?x?|–|0)', page_3[item].pop(15))\n",
    "    page_3[item] = page_3[item][:15] + data_15_to_17 + page_3[item][15:] \n",
    "page_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the length of each data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for item in page_3:\n",
    "    if len(item) == 22:\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct. Moving to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(len(page_3)):\n",
    "    data_19_to_20 = re.findall(r'([1-9][0-9]?x?|–)', page_3[item].pop(19))\n",
    "    page_3[item] = page_3[item][:19] + data_19_to_20 + page_3[item][19:] \n",
    "page_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for item in page_3:\n",
    "    if len(item) == 23:\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All rows are split into same and correct length. However, it does not mean the result is correct.\n",
    "\n",
    "The `'Uganda397332' to 'Uganda','39','73' and '32'` and `'192817938978' to '19','28','17','93','89' and '78'` can be checked by using the previous `'total', 'urban' and 'rural'` idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in page_3:\n",
    "    if '–' not in item[2] and '–' not in item[3]:\n",
    "        if int(item[1]) > int(item[2]) and int(item[1]) > int(item[3]):\n",
    "            print(item)\n",
    "        elif int(item[1]) < int(item[2]) and int(item[1]) < int(item[3]):\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in page_3:\n",
    "    if '–' not in item[5] and '–' not in item[6]:\n",
    "        if int(item[4]) > int(item[5]) and int(item[4]) > int(item[6]):\n",
    "            print(item)\n",
    "        elif int(item[4]) < int(item[5]) and int(item[4]) < int(item[6]):\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data in other columns does not have relation between each, we can just use the 'greed' of `? Quantifier` to check if there is any abnormal data, e.g if data is not in `'-', '0'` and `'100'`, most of them should be two-digit number, and some of them contain `'x'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[7]:\n",
    "        if len(row[7]) < 2 and int(row[7]) != 0 and int(row[7]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[8]:\n",
    "        if len(row[8]) < 2 and int(row[8]) != 0 and int(row[8]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[9]:\n",
    "        if len(row[9]) < 2 and int(row[9]) != 0 and int(row[9]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[15]:\n",
    "        if len(row[15]) < 2 and int(row[15]) != 0 and int(row[15]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[16]:\n",
    "        if len(row[16]) < 2 and int(row[16]) != 0 and int(row[16]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[17]:\n",
    "        if len(row[17]) < 2 and int(row[17]) != 0 and int(row[17]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the original PDF file, the error can be found, that is the merged \"`47775\"` is splited into `\"47\"`, `\"77\"` and `\"5\"`, while in PDF they are `\"47\"`, `\"7\"` and `\"75\"`. So we need to re-split the incorrect data as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in page_3:\n",
    "    if '–' not in item[17]:\n",
    "        if int(item[17]) < 10: \n",
    "            data1 = re.findall(r'(\\d)(\\d)', item[16])\n",
    "            data2 = re.findall(r'(\\d)', item[17])\n",
    "            item[16] = data1[0][0]\n",
    "            item[17] = data1[0][1] + data2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if row[0] == \"Venezuela (Bolivarian Republic of)\":\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct. Continuing checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[19]:\n",
    "        if len(row[19]) < 2 and int(row[19]) != 0 and int(row[19]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in page_3:\n",
    "    if '–' not in row[20]:\n",
    "        if len(row[20]) < 2 and int(row[20]) != 0 and int(row[20]) != 100: \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After confirming the correctness, we can merge all data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_pdf = page_0_to_2 + page_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the integrity of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entire_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for item in entire_pdf:\n",
    "    if len(item) == 23:\n",
    "        num += 1\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(entire_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create DataFrame by passing a list of object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(entire_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the requirement, \"x\" must be dropped in your script, so we replace 'x' with ''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('x','',regex=True,inplace=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And based on the sample figure, the \"–\" should be replaced as \"NaN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('–',np.nan,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to reset the index(using country names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index(data[0].values)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting the redundant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(0,axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindexing all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = list(range(len(data.columns))) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.rename('Country Name', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to store the data in CSV format using Pandas `'to_csv'` function, and `encoding = 'utf-16'` and `sep = '\\t'` will also be used to address non-English characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./health.csv',encoding='UTF-16',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF file is not easy to parse, despite using existing package like pdftables, cause there may contain many unexcepted merge of data. Due to the fact that data can be very diverse in terms of length and type, regular expression may not able to handle all ppossibility, so using the relationship between data or other way that we can figure to check the correctness of result is very necessary.\n",
    "\n",
    "The main outcomes achieved while completing this task were:\n",
    "- Thinking out right regular expressions to get desired result\n",
    "- Using effective and efficient way to check the correctness of result\n",
    "- Understanding data and the relationship between and the meaning behind data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moodle FIT5196 Week3. *parsing PDF,* Retrieved from: https://moodle.vle.monash.edu/mod/resource/view.php?id=4845787\n",
    "- Python sofyware foundation.(2018) *6.2. re — Regular expression operations.* Retrieved from https://docs.python.org/3/library/re.html\n",
    "- Python sofyware foundation.(2018) *5. Data Structures.* Retrieved from https://docs.python.org/3.6/tutorial/datastructures.html\n",
    "- Chris Albon (2017 December,20) *Replacing Values In pandas* Retrived from: https://chrisalbon.com/python/data_wrangling/pandas_replace_values/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
